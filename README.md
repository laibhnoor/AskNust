# AI-Powered RAG Chatbot (FastAPI + LangChain) #
 
This project is a Retrieval-Augmented Generation (RAG) chatbot built with FastAPI and LangChain that allows users to query documents (PDFs, CSVs, etc.) and get context-aware answers in natural language.

It uses FAISS for vector storage, OpenAI GPT (or HuggingFace models) for LLM responses, and supports conversational memory so that follow-up questions remain contextual.

ğŸš€ Features

âœ… Document Loader â€“ Loads multiple PDFs and CSVs from a data/ folder

âœ… Chunking & Embeddings â€“ Splits documents into manageable chunks and generates vector embeddings

âœ… FAISS Vector Database â€“ Stores document embeddings locally for fast retrieval

âœ… RAG Pipeline â€“ Retrieves most relevant chunks and passes them to an LLM for answer generation

âœ… Conversational Memory â€“ Remembers chat history for contextual follow-ups

âœ… FastAPI Backend â€“ Provides REST API endpoints for querying

âœ… CORS Enabled â€“ Works seamlessly with React (or any frontend)


##  ğŸ› ï¸ Tech Stack ##

Backend: FastAPI

Document Processing: LangChain + FAISS

LLM: OpenAI GPT-3.5 (configurable)

Embeddings: OpenAI Embeddings or HuggingFace Sentence Transformers

Memory: ConversationBufferMemory (LangChain)


seecs-ai-receptionist/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py              # Main backend server (FastAPI)
â”‚   â”œâ”€â”€ ingest.py           # Script to load & embed institutional documents
â”‚   â”œâ”€â”€ retriever.py        # RAG pipeline logic
â”‚   â”œâ”€â”€ requirements.txt    # Python dependencies
â”‚   â”œâ”€â”€ .env                # Environment variables (API keys, DB paths)
â”‚   â””â”€â”€ data/
â”‚       â””â”€â”€ knowledge_base/ # PDFs, CSVs, docs to embed
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/     # React components (Chat UI, input box, history)
â”‚   â”‚   â”œâ”€â”€ App.jsx
â”‚   â”‚   â””â”€â”€ main.jsx
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.js
â”‚
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

## âš¡ Setup & Usage ##    
### 1ï¸âƒ£ Clone the Repository
git clone https://github.com/laibhnoor/rag-chatbot.git
cd rag-chatbot/backend

### 2ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

### 3ï¸âƒ£ Configure Environment Variables
Create a .env file in the backend/ folder:
OPENAI_API_KEY=your_openai_api_key_here

### 4ï¸âƒ£ Build the Vector Database
python ingest.py

This will:

Load all PDFs/CSVs from data/

Split into chunks

Create embeddings

Save FAISS index locally in vectorstore/

### 5ï¸âƒ£ Run the FastAPI Server
uvicorn main:app --reload

You should see:

âœ… FastAPI is running

Visit http://localhost:8000 to confirm.






